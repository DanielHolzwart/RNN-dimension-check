{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZAz+kah9Gfd5ZgolWTg/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielHolzwart/RNN-dimension-check/blob/main/RNN_dimension_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kglpwoA1dvF_"
      },
      "outputs": [],
      "source": [
        "#quick check to evaluate the dimensions of an RNN with 2 layers\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "rnn_layer = nn.RNN(input_size=5, hidden_size=4,num_layers=2, batch_first=True)\n",
        "\n",
        "w_xh0 = rnn_layer.weight_ih_l0\n",
        "w_hh0 = rnn_layer.weight_hh_l0\n",
        "b_xh0 = rnn_layer.bias_ih_l0\n",
        "b_hh0 = rnn_layer.bias_hh_l0\n",
        "w_xh1 = rnn_layer.weight_ih_l1\n",
        "w_hh1 = rnn_layer.weight_hh_l1\n",
        "b_xh1 = rnn_layer.bias_ih_l1\n",
        "b_hh1 = rnn_layer.bias_hh_l1\n",
        "print('W_xh shape:', w_xh0.shape)\n",
        "print('W_hh shape:', w_hh0.shape)\n",
        "print('b_xh shape:', b_xh0.shape)\n",
        "print('b_hh shape:', b_hh0.shape)\n",
        "print('W_xh shape:', w_xh1.shape)\n",
        "print('W_hh shape:', w_hh1.shape)\n",
        "print('b_xh shape:', b_xh1.shape)\n",
        "print('b_hh shape:', b_hh1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMpjHETad268",
        "outputId": "d7e46fd8-2d2a-4c44-f075-19ec03766d45"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_xh shape: torch.Size([4, 5])\n",
            "W_hh shape: torch.Size([4, 4])\n",
            "b_xh shape: torch.Size([4])\n",
            "b_hh shape: torch.Size([4])\n",
            "W_xh shape: torch.Size([4, 4])\n",
            "W_hh shape: torch.Size([4, 4])\n",
            "b_xh shape: torch.Size([4])\n",
            "b_hh shape: torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#putting the weights and bias into a dictonary for looping in the next step\n",
        "w_xh = {0 : w_xh0, 1 : w_xh1}\n",
        "w_hh = {0 : w_hh0, 1 : w_hh1}\n",
        "b_xh = {0 : b_xh0, 1 : b_xh1}\n",
        "b_hh = {0 : b_hh0, 1 : b_hh1}"
      ],
      "metadata": {
        "id": "-yYQbG_omQb6"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float() #for words the dimensions of x_seq would be (sequence_length, embedding dimension)\n",
        "# output of the simple RNN:\n",
        "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))\n",
        "## manually computing the output:\n",
        "out_man = [[],[]]\n",
        "for layers in range(rnn_layer.num_layers):\n",
        "    for t in range(3):\n",
        "        if layers == 0:\n",
        "            xt = torch.reshape(x_seq[t], (1, 5))\n",
        "        else:\n",
        "            xt = out_man[layers - 1][t]\n",
        "        print(f'Time step {t} at layer {layers} =>')\n",
        "        print('Input:', xt.detach().numpy())\n",
        "        ht = torch.matmul(xt, torch.transpose(w_xh[layers], 0, 1))\n",
        "        print('Hidden:', ht.detach().numpy())\n",
        "        if t > 0:\n",
        "            prev_h = out_man[layers][t-1]\n",
        "        else:\n",
        "            prev_h = torch.zeros((ht.shape))\n",
        "        ot = ht + torch.matmul(prev_h, torch.transpose(w_hh[layers], 0, 1)) + b_hh[layers] + b_xh[layers]\n",
        "        ot = torch.tanh(ot)\n",
        "        out_man[layers].append(ot)\n",
        "        print('Output (manual) :', ot.detach().numpy())\n",
        "        if layers == (rnn_layer.num_layers - 1):\n",
        "            print('RNN output', output[:, t].detach().numpy())\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wyyTGZQd_S3",
        "outputId": "1946d8ca-4d00-4d9a-c325-376b490f0bb4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time step 0 at layer 0 =>\n",
            "Input: [[1. 1. 1. 1. 1.]]\n",
            "Hidden: [[-0.29602224  0.45965433  0.11465555  0.6181393 ]]\n",
            "Output (manual) : [[0.56055534 0.16334416 0.6066464  0.3728287 ]]\n",
            "\n",
            "Time step 1 at layer 0 =>\n",
            "Input: [[2. 2. 2. 2. 2.]]\n",
            "Hidden: [[-0.5920445   0.91930866  0.22931111  1.2362787 ]]\n",
            "Output (manual) : [[0.05261802 0.67545795 0.6944291  0.6304203 ]]\n",
            "\n",
            "Time step 2 at layer 0 =>\n",
            "Input: [[3. 3. 3. 3. 3.]]\n",
            "Hidden: [[-0.88806677  1.378963    0.34396666  1.8544179 ]]\n",
            "Output (manual) : [[-0.350783    0.8996122   0.90739036  0.69391143]]\n",
            "\n",
            "Time step 0 at layer 1 =>\n",
            "Input: [[0.56055534 0.16334416 0.6066464  0.3728287 ]]\n",
            "Hidden: [[-0.21185923 -0.47037655  0.5837881   0.17492902]]\n",
            "Output (manual) : [[-0.3641145  -0.5368899   0.14999884  0.32872772]]\n",
            "RNN output [[-0.3641145  -0.5368899   0.14999884  0.32872772]]\n",
            "\n",
            "Time step 1 at layer 1 =>\n",
            "Input: [[0.05261802 0.67545795 0.6944291  0.6304203 ]]\n",
            "Hidden: [[ 0.06813398 -0.528718    0.53069365  0.08260797]]\n",
            "Output (manual) : [[ 0.0329843  -0.453678    0.40445513  0.20276399]]\n",
            "RNN output [[ 0.0329843  -0.453678    0.40445513  0.20276402]]\n",
            "\n",
            "Time step 2 at layer 1 =>\n",
            "Input: [[-0.350783    0.8996122   0.90739036  0.69391143]]\n",
            "Hidden: [[ 0.18481708 -0.600268    0.5255075   0.0919379 ]]\n",
            "Output (manual) : [[ 0.06962731 -0.5984205   0.3163194   0.32946417]]\n",
            "RNN output [[ 0.06962733 -0.5984205   0.3163194   0.32946417]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finally, we can also quickly manually compare the manual output with hn coming from the rnn_layer as defined above\n",
        "print('--- checking out_man to outputs --- \\n')\n",
        "for i in range(3):\n",
        "    print(torch.allclose(out_man[rnn_layer.num_layers-1][i],output[:,i,:]))\n",
        "print()\n",
        "print('--- checking hn to last output --- \\n')\n",
        "for i in range(rnn_layer.num_layers):\n",
        "    print(torch.allclose(out_man[i][2],hn[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y683Dc1qqZM",
        "outputId": "9ae2f7cf-43e5-4c0d-d0dc-ccac267b9bf1"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- checking out_man to outputs --- \n",
            "\n",
            "True\n",
            "True\n",
            "True\n",
            "\n",
            "--- checking hn to last output --- \n",
            "\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzpRN9Feu-Me"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}